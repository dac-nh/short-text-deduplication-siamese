{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from model.model import sim_trip_classification\n",
    "from model.SelfAttentionModel import StructuredSelfAttention\n",
    "from utils.data_loader import (\n",
    "    load_data_set,\n",
    "    load_word_to_index,\n",
    "    load_char_to_index,\n",
    "    load_triplet_orders,\n",
    "    load_padded_data,\n",
    "    load_triplet,\n",
    "    generate_embedding,\n",
    ")\n",
    "from utils.pretrained_glove_embeddings import load_glove_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# main_path = \"/data/dac/dedupe-project/openmap/\"  # Open map dataset\n",
    "main_path = \"/data/dac/dedupe-project/new/\"  # Lab dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(file_path, retrain=True):\n",
    "    # Load dataset\n",
    "    df = load_data_set(file_path)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    # get char to index and embedding whole dataset\n",
    "    embedding_index = load_char_to_index(df)\n",
    "    embeddings = generate_embedding(embedding_index, embedding_dim=50)\n",
    "    # Get X and X_len as matrix\n",
    "    X, X_len = load_padded_data(df, embedding_index, char_level=True)\n",
    "\n",
    "    def truncate_non_string(X, X_len):\n",
    "        # Drop rows that have length of word vector = 0\n",
    "        truncate_index = [i for i in range(0, len(X_len)) if X_len[i] <= 0]\n",
    "        X, X_len = (\n",
    "            np.delete(X, truncate_index, axis=0),\n",
    "            np.delete(X_len, truncate_index, axis=0),\n",
    "        )\n",
    "\n",
    "        return X, X_len, sorted(truncate_index, reverse=True)\n",
    "\n",
    "    X, X_len, truncate_index = truncate_non_string(X, X_len)\n",
    "    df.drop(index=truncate_index, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df, X, X_len, embeddings, embedding_index\n",
    "\n",
    "\n",
    "def to_cuda(loader, device):\n",
    "    return [load.to(device) for load in loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load character to index successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e2cb7bbb2840d38a9c3fedeedca612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=28896, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    }
   ],
   "source": [
    "# set cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(device)\n",
    "\n",
    "# random_augment_train.csv\n",
    "# \"new_generated_labeled_data.csv\"\n",
    "full_generated_data_path = \"random_augment_train.csv\"  # Local dataset\n",
    "open_map_data_path = \"openmap-us-train.csv\"  # Open map dataset\n",
    "# Remember to set open map in train data\n",
    "df, X, X_len, embeddings, embedding_index = prepare_data(\n",
    "    main_path + full_generated_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(X_len)\n",
    "# plt.savefig(\"/data/dac/dedupe-project/image/length_X.eps\", format=\"eps\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DataLoader and Triplet orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc4056b2f82421085b3acaddb6bd1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[Generate Triplet Dataset] Start thread', max=137, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7ef407069441198f4755b2bd75e2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[Generate Triplet Dataset] Join thread', max=137, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading triplet order successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e910995a794d5cb43859346fd1d4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Load triplets', max=2070054, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load triplet data successfully!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "df_triplet_orders = load_triplet_orders(df)\n",
    "print(\"Loading triplet order successfully!\")\n",
    "anc_loader, pos_loader, neg_loader = load_triplet(\n",
    "    np.array(X), X_len, df_triplet_orders, batch_size=batch_size\n",
    ")\n",
    "print(\"Load triplet data successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Create train file as pair for some methods\n",
    "# train_pair_arr = []\n",
    "# for row in df_triplet_orders.loc[:20000, :].itertuples():\n",
    "#     anchor = row[2]\n",
    "#     pos = row[3]\n",
    "#     neg = row[4]\n",
    "\n",
    "#     pair = {}\n",
    "#     pair[\"address\"] = df.iloc[anchor].content\n",
    "#     pair[\"duplicated_address\"] = df.iloc[pos].content\n",
    "#     pair[\"similar\"] = 1\n",
    "#     train_pair_arr.append(pair)\n",
    "\n",
    "#     pair = {}\n",
    "#     pair[\"address\"] = df.iloc[anchor].content\n",
    "#     pair[\"duplicated_address\"] = df.iloc[neg].content\n",
    "#     pair[\"similar\"] = 0\n",
    "#     train_pair_arr.append(pair)\n",
    "\n",
    "# pd.DataFrame(train_pair_arr).to_csv(\n",
    "#     \"/data/dac/dedupe-project/train_as_pair.csv\", encoding=\"utf-8\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare validate dataset\n",
    "1. Load dataset\n",
    "2. Pre-processing\n",
    "3. Create pair of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/dac/dedupe-project/test/\"\n",
    "test_df = pd.read_csv(path + \"test_address_3.csv\", encoding=\"ISO-8859-1\")\n",
    "test_df.fillna(\"\", inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df_1 = test_df.loc[:, [\"address\"]]\n",
    "test_df_1[\"content\"] = (\n",
    "    test_df_1[\"address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    "    .str.replace(\"null\", \"\")\n",
    "    .str.replace(\"nan\", \"\")\n",
    ")\n",
    "test_df_2 = test_df.loc[:, [\"duplicated_address\"]]\n",
    "test_df_2[\"content\"] = (\n",
    "    test_df_2[\"duplicated_address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    "    .str.replace(\"null\", \"\")\n",
    "    .str.replace(\"nan\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(test_df_1, test_df_2):\n",
    "    # Data Preparation pipeline\n",
    "    # Create Dataloader based on two dataframe have row 'content' in it\n",
    "    X1, X1_lens = load_padded_data(pd.DataFrame(test_df_1), embedding_index)\n",
    "\n",
    "    X2, X2_lens = load_padded_data(pd.DataFrame(test_df_2), embedding_index)\n",
    "\n",
    "    # Drop rows that have length of word vector = 0\n",
    "    truncate_index = [\n",
    "        i for i in range(0, len(X1_lens)) if (X1_lens[i] <= 0 or X2_lens[i] <= 0)\n",
    "    ]\n",
    "    X1, X1_lens = (\n",
    "        np.delete(X1, truncate_index, axis=0),\n",
    "        np.delete(X1_lens, truncate_index, axis=0),\n",
    "    )\n",
    "    X2, X2_lens = (\n",
    "        np.delete(X2, truncate_index, axis=0),\n",
    "        np.delete(X2_lens, truncate_index, axis=0),\n",
    "    )\n",
    "\n",
    "    def create_data_loader(X, batch_size=batch_size):\n",
    "        X, X_lens = np.array(X[0]), np.array(X[1])\n",
    "\n",
    "        # Create data loader\n",
    "        data = TensorDataset(\n",
    "            torch.from_numpy(X).type(torch.LongTensor), torch.ByteTensor(X_lens)\n",
    "        )\n",
    "        loader = DataLoader(data, batch_size=batch_size, drop_last=False)\n",
    "        return loader\n",
    "\n",
    "    return (\n",
    "        create_data_loader([X1, X1_lens]),\n",
    "        create_data_loader([X2, X2_lens]),\n",
    "        truncate_index,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_test(n, test_df_1, test_df_2):\n",
    "    # Generate small test based on ground truth\n",
    "    test_df_1a = pd.DataFrame()\n",
    "    test_df_1b = pd.DataFrame()\n",
    "\n",
    "    for i1, i2 in shuffle(list(itertools.combinations(test_df_1.index, 2)))[:n]:\n",
    "        try:\n",
    "            test_df_1a = test_df_1a.append(test_df_1.iloc[i1, :])\n",
    "            test_df_1b = test_df_1b.append(test_df_2.iloc[i2, :])\n",
    "        except:\n",
    "            print(i1, i2)\n",
    "\n",
    "    test_df_1b = test_df_1b.append(test_df_1)\n",
    "    test_df_1a = test_df_1a.append(test_df_2)\n",
    "\n",
    "    test_df_1a.reset_index(inplace=True)\n",
    "    test_df_1b.reset_index(inplace=True)\n",
    "\n",
    "    return test_df_1a, test_df_1b\n",
    "\n",
    "\n",
    "def validate(model, X1, X2, device):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for a, b in tqdm(zip(X1, X2)):\n",
    "        # Send data to graphic card - Cuda0\n",
    "        a, b = to_cuda(a, device), to_cuda(b, device)\n",
    "        with torch.no_grad():\n",
    "            # Predict\n",
    "            y_pred_curr = model(a, b).data.numpy()\n",
    "            y_pred_curr[y_pred_curr <= 0] = 0\n",
    "            y_pred_curr[y_pred_curr > 0] = 1\n",
    "            y_pred = np.concatenate([y_pred, y_pred_curr])\n",
    "            # Get the truth label\n",
    "            y_true_curr = np.ones(len(dist))\n",
    "            y_true = np.concatenate([y_true, y_true_curr])\n",
    "    print(\n",
    "        \"Accuracy:\\t{}\\t\\tF1-score:\\t{}\\t\".format(\n",
    "            round(accuracy_score(y_true, y_pred), 4), round(f1_score(y_true, y_pred), 4)\n",
    "        ),\n",
    "        end=\"\",\n",
    "    )\n",
    "    print(\n",
    "        \"Precision:\\t{}\\t\\tRecall:\\t{}\".format(\n",
    "            round(precision_score(y_true, y_pred), 4),\n",
    "            round(recall_score(y_true, y_pred), 4),\n",
    "        ),\n",
    "        end=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26559ac89fbe407ca022f74f77ddbe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=1225, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7a561518334ebebe6a6c3fbfc1bc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=1225, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    }
   ],
   "source": [
    "test_df_1a, test_df_1b = create_test(1176, test_df_1, test_df_2)\n",
    "X1, X2, drop = data_loader(test_df_1a, test_df_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Siamese\n",
    "Build, train and validate Triplet Siamese Model\n",
    "1. Embedding\n",
    "2. Deep Neural Network (Loss: Minimize the loss by maximize the distance between positive and negative)\n",
    "3. Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_trip_classification(\n",
      "  (embeddings): Embedding(59, 50)\n",
      "  (gru): GRU(50, 50, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (linear_final): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (gru_combined): GRU(2, 5, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (linear_class): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Self-attention triplet model\n",
    "# model = StructuredSelfAttention(embeddings=embeddings, n_classes=50).to(device)\n",
    "\n",
    "# triplet_siamese_300d_bi_gru: hit\n",
    "# triplet_siamese_50d_bi_gru_random: outperform\n",
    "triplet_model_path = \"/data/dac/dedupe-project/new/model/stc_l1_h50_m7_n30\"\n",
    "\n",
    "lr = 0.1\n",
    "margin = 0.4\n",
    "# Load model & optimizer\n",
    "model = sim_trip_classification(\n",
    "    embeddings=embeddings, layers=1, hid_dim=50, max_len=7, n_classes=30\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load model and optimizer\n",
    "checkpoint = torch.load(triplet_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869f17d817044a9a89497a5ac1298757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'batch_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cafa925e5c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         )\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Append to batch list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dedupe/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dedupe-project/short-text-deduplication-siamese/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# Training purpose - Triplet input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             anchors, positives, negatives = (\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mforward_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mforward_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mforward_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dedupe-project/short-text-deduplication-siamese/model/model.py\u001b[0m in \u001b[0;36mforward_detail\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# batch, steps, hid_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dedupe/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \"\"\"\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'batch_sizes'"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 2\n",
    "best_lost = None\n",
    "early_stopping_steps = 5\n",
    "\n",
    "loss_list = []\n",
    "average_list = []\n",
    "model.train()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\", total=epochs):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "\n",
    "    for batch, [anc_x, pos_x, neg_x] in enumerate(\n",
    "        zip(anc_loader, pos_loader, neg_loader)\n",
    "    ):\n",
    "        # Training model per batch\n",
    "        # Send data to graphic card - Cuda\n",
    "        anc_x, pos_x, neg_x = (\n",
    "            to_cuda(anc_x, device),\n",
    "            to_cuda(pos_x, device),\n",
    "            to_cuda(neg_x, device),\n",
    "        )\n",
    "        loss = model(anc_x, pos_x, neg_x)\n",
    "\n",
    "        # Append to batch list\n",
    "        avg_loss += float(loss)\n",
    "\n",
    "        # Gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\n",
    "            \"\\rBatch:\\t{}\\tLoss:\\t{}\".format(batch, round(float(loss), 4)), end=\"\",\n",
    "        )\n",
    "        validate(model, X1, X2, device)\n",
    "    # Average loss all epochs\n",
    "    avg_loss /= len(anc_loader)\n",
    "\n",
    "    loss_list.append(avg_loss)\n",
    "    print(\n",
    "        \"\\rEpoch:\\t{}\\tAverage Loss:\\t{}\".format(\n",
    "            epoch,\n",
    "            round(avg_loss, 4)\n",
    "        )\n",
    "    )\n",
    "    if best_lost is None or best_lost > avg_loss:\n",
    "        best_lost = avg_loss\n",
    "        forward_index = 0\n",
    "        #         Save model\n",
    "        torch.save(\n",
    "            {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()},\n",
    "            triplet_model_path,\n",
    "        )\n",
    "    else:\n",
    "        # Early stopping after reachs {early_stopping_steps} steps\n",
    "        forward_index += 1\n",
    "        if forward_index == early_stopping_steps or best_lost == 0:\n",
    "            break\n",
    "    if best_lost < 1:\n",
    "        break\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(\n",
    "    {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()},\n",
    "    triplet_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fodor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(df1, df2, pair):\n",
    "    df_out1 = []\n",
    "    df_out2 = []\n",
    "    y = []\n",
    "    for row in pair.itertuples():\n",
    "        # Create two test dataframe based on index file\n",
    "        # index, l_id, r_id, label\n",
    "        df_out1.append(df1[\"content\"][df1[\"id\"] == row[1]])\n",
    "        df_out2.append(df2[\"content\"][df2[\"id\"] == row[2]])\n",
    "        y.append(row[3])\n",
    "\n",
    "    df_out1 = pd.DataFrame(pd.concat(df_out1))\n",
    "    df_out2 = pd.DataFrame(pd.concat(df_out2))\n",
    "\n",
    "    # Create DataLoader\n",
    "    X1, X2, drop = data_loader(df_out1, df_out2)\n",
    "\n",
    "    return X1, X2, y, df_out1, df_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6703 melrose ave.   los angeles californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>67 n. raymond ave.   los angeles asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1915 fillmore st.   san francisco italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>160 e. 64th st.   new york american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3570 las vegas blvd. s   las vegas continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3201 fillmore st.   san francisco mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>730 n. la cienega blvd.   los angeles french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>224 ponce de leon ave. atlantasouthern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>3645 las vegas blvd. s   las vegas buffets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>249 e. 50th st.   new york french</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content\n",
       "6         6703 melrose ave.   los angeles californian\n",
       "22             67 n. raymond ave.   los angeles asian\n",
       "501         1915 fillmore st.   san francisco italian\n",
       "38                160 e. 64th st.   new york american\n",
       "70     3570 las vegas blvd. s   las vegas continental\n",
       "..                                                ...\n",
       "108   3201 fillmore st.   san francisco mediterranean\n",
       "133      730 n. la cienega blvd.   los angeles french\n",
       "86             224 ponce de leon ave. atlantasouthern\n",
       "424        3645 las vegas blvd. s   las vegas buffets\n",
       "44                  249 e. 50th st.   new york french\n",
       "\n",
       "[189 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>8284 melrose ave.   los angeles   french bistro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>67 n. raymond ave. pasadenachinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1870 fillmore st.   san francisco american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>160 e. 64th st.   new york city   french bistro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3595 las vegas blvd. s.   las vegas continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3127 fillmore st.   san francisco   american ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>903 n. la cienega blvd.   w. hollywood   fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>600 ponce de leon ave. atlantaitalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3799 las vegas blvd. s.   las vegas seafood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>243 e. 58th st.   new york city italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "230   8284 melrose ave.   los angeles   french bistro \n",
       "240                 67 n. raymond ave. pasadenachinese\n",
       "214         1870 fillmore st.   san francisco american\n",
       "256   160 e. 64th st.   new york city   french bistro \n",
       "130    3595 las vegas blvd. s.   las vegas continental\n",
       "..                                                 ...\n",
       "326   3127 fillmore st.   san francisco   american ...\n",
       "229   903 n. la cienega blvd.   w. hollywood   fren...\n",
       "156              600 ponce de leon ave. atlantaitalian\n",
       "125        3799 las vegas blvd. s.   las vegas seafood\n",
       "251            243 e. 58th st.   new york city italian\n",
       "\n",
       "[189 rows x 1 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922ed33e5e53463ea9ffb92090dfa330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=189, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d1b1e8099342a79faee8fbf771d881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=189, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f64aea55ed411fb8e6e8ae1a92334d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=567, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a58f7193184bbf95d02149f9c6c127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Padding', max=567, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load padded data successfully!\n"
     ]
    }
   ],
   "source": [
    "# Prepare data to input as DataLoader\n",
    "fd_a = pd.read_csv(path + \"fodor/tableA.csv\")\n",
    "fd_a[\"content\"] = fd_a[\"addr\"] + fd_a[\"city\"] + fd_a[\"type\"]\n",
    "fd_a[\"content\"] = fd_a[\"content\"].str.replace(\"'\", \"\").str.replace(\"`\", \" \")\n",
    "\n",
    "fd_b = pd.read_csv(path + \"fodor/tableB.csv\")\n",
    "fd_b[\"content\"] = fd_b[\"addr\"] + fd_b[\"city\"] + fd_b[\"type\"]\n",
    "fd_b[\"content\"] = fd_b[\"content\"].str.replace(\"'\", \"\").str.replace(\"`\", \" \")\n",
    "\n",
    "fd_test_pair = pd.read_csv(path + \"fodor/test.csv\")\n",
    "fd_train_pair = pd.read_csv(path + \"fodor/train.csv\")\n",
    "\n",
    "X1_test, X2_test, y_test, df_test_1, df_test_2 = create_pairs(fd_a, fd_b, fd_test_pair)\n",
    "X1_train, X2_train, y_train, df_train_1, df_train_2 = create_pairs(\n",
    "    fd_a, fd_b, fd_train_pair\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "      <th>class</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>` arnie morton \\ 's of chicago '</td>\n",
       "      <td>' 435 s. la cienega blv . '</td>\n",
       "      <td>` los angeles '</td>\n",
       "      <td>310/246 -1501</td>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>435 s. la cienega blv .   los angeles american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>` art \\ 's delicatessen '</td>\n",
       "      <td>' 12224 ventura blvd. '</td>\n",
       "      <td>` studio city '</td>\n",
       "      <td>818/762 -1221</td>\n",
       "      <td>american</td>\n",
       "      <td>1</td>\n",
       "      <td>12224 ventura blvd.   studio city american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>` hotel bel-air '</td>\n",
       "      <td>' 701 stone canyon rd. '</td>\n",
       "      <td>` bel air '</td>\n",
       "      <td>310/472 -1211</td>\n",
       "      <td>californian</td>\n",
       "      <td>2</td>\n",
       "      <td>701 stone canyon rd.   bel air californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>` cafe bizou '</td>\n",
       "      <td>' 14016 ventura blvd. '</td>\n",
       "      <td>` sherman oaks '</td>\n",
       "      <td>818/788 -3536</td>\n",
       "      <td>french</td>\n",
       "      <td>3</td>\n",
       "      <td>14016 ventura blvd.   sherman oaks french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>campanile</td>\n",
       "      <td>' 624 s. la brea ave. '</td>\n",
       "      <td>` los angeles '</td>\n",
       "      <td>213/938 -1447</td>\n",
       "      <td>american</td>\n",
       "      <td>4</td>\n",
       "      <td>624 s. la brea ave.   los angeles american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>528</td>\n",
       "      <td>` yank sing '</td>\n",
       "      <td>' 427 battery st. '</td>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>415/541 -4949</td>\n",
       "      <td>asian</td>\n",
       "      <td>528</td>\n",
       "      <td>427 battery st.   san francisco asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td>` yaya cuisine '</td>\n",
       "      <td>' 1220 9th ave. '</td>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>415/566 -6966</td>\n",
       "      <td>` greek and middle eastern '</td>\n",
       "      <td>529</td>\n",
       "      <td>1220 9th ave.   san francisco   greek and mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td>` yoyo tsumami bistro '</td>\n",
       "      <td>' 1611 post st. '</td>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>415/922 -7788</td>\n",
       "      <td>french</td>\n",
       "      <td>530</td>\n",
       "      <td>1611 post st.   san francisco french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>zarzuela</td>\n",
       "      <td>' 2000 hyde st. '</td>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>415/346 -0800</td>\n",
       "      <td>` mexican/latin american/spanish '</td>\n",
       "      <td>531</td>\n",
       "      <td>2000 hyde st.   san francisco   mexican/latin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>` zuni cafe &amp; grill '</td>\n",
       "      <td>' 1658 market st. '</td>\n",
       "      <td>` san francisco '</td>\n",
       "      <td>415/552 -2522</td>\n",
       "      <td>mediterranean</td>\n",
       "      <td>532</td>\n",
       "      <td>1658 market st.   san francisco mediterranean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              name                         addr  \\\n",
       "0      0  ` arnie morton \\ 's of chicago '  ' 435 s. la cienega blv . '   \n",
       "1      1         ` art \\ 's delicatessen '      ' 12224 ventura blvd. '   \n",
       "2      2                 ` hotel bel-air '     ' 701 stone canyon rd. '   \n",
       "3      3                    ` cafe bizou '      ' 14016 ventura blvd. '   \n",
       "4      4                         campanile      ' 624 s. la brea ave. '   \n",
       "..   ...                               ...                          ...   \n",
       "528  528                     ` yank sing '          ' 427 battery st. '   \n",
       "529  529                  ` yaya cuisine '            ' 1220 9th ave. '   \n",
       "530  530           ` yoyo tsumami bistro '            ' 1611 post st. '   \n",
       "531  531                          zarzuela            ' 2000 hyde st. '   \n",
       "532  532             ` zuni cafe & grill '          ' 1658 market st. '   \n",
       "\n",
       "                  city          phone                                type  \\\n",
       "0      ` los angeles '  310/246 -1501                            american   \n",
       "1      ` studio city '  818/762 -1221                            american   \n",
       "2          ` bel air '  310/472 -1211                         californian   \n",
       "3     ` sherman oaks '  818/788 -3536                              french   \n",
       "4      ` los angeles '  213/938 -1447                            american   \n",
       "..                 ...            ...                                 ...   \n",
       "528  ` san francisco '  415/541 -4949                               asian   \n",
       "529  ` san francisco '  415/566 -6966        ` greek and middle eastern '   \n",
       "530  ` san francisco '  415/922 -7788                              french   \n",
       "531  ` san francisco '  415/346 -0800  ` mexican/latin american/spanish '   \n",
       "532  ` san francisco '  415/552 -2522                       mediterranean   \n",
       "\n",
       "     class                                            content  \n",
       "0        0     435 s. la cienega blv .   los angeles american  \n",
       "1        1         12224 ventura blvd.   studio city american  \n",
       "2        2         701 stone canyon rd.   bel air californian  \n",
       "3        3          14016 ventura blvd.   sherman oaks french  \n",
       "4        4         624 s. la brea ave.   los angeles american  \n",
       "..     ...                                                ...  \n",
       "528    528              427 battery st.   san francisco asian  \n",
       "529    529   1220 9th ave.   san francisco   greek and mid...  \n",
       "530    530               1611 post st.   san francisco french  \n",
       "531    531   2000 hyde st.   san francisco   mexican/latin...  \n",
       "532    532      1658 market st.   san francisco mediterranean  \n",
       "\n",
       "[533 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177683d11084beaa39d6e4e48308726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\t0.2222\t\tF1-score:\t0.2304\tPrecision:\t0.1302\t\tRecall:\t1.0"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "pred_list = []\n",
    "for a, b in tqdm(zip(X1, X2)):\n",
    "    # Send data to graphic card - Cuda0\n",
    "    a, b = to_cuda(a, device), to_cuda(b, device)\n",
    "    with torch.no_grad():\n",
    "        a, b = model(a, b)\n",
    "        a, b = a.cpu(), b.cpu()\n",
    "        a = a.reshape(a.shape[0], -1)\n",
    "        b = b.reshape(b.shape[0], -1)\n",
    "        #         att1 = att1.cpu()\n",
    "        #         att2 = att2.cpu()\n",
    "        dist = np.array(\n",
    "            [\n",
    "                cosine_similarity([a[i].numpy()], [b[i].numpy()])\n",
    "                for i in range(0, len(a))\n",
    "            ]\n",
    "        ).flatten()\n",
    "        y_pred_curr = np.ones(len(dist))\n",
    "        y_pred_curr[np.where(dist < 0.35039073)[0]] = 0\n",
    "        y_pred = np.concatenate([y_pred, y_pred_curr])\n",
    "\n",
    "        pred_list = np.concatenate([pred_list, dist])\n",
    "\n",
    "print(\n",
    "    \"Accuracy:\\t{}\\t\\tF1-score:\\t{}\\t\".format(\n",
    "        round(accuracy_score(y_test, y_pred), 4), round(f1_score(y_test, y_pred), 4)\n",
    "    ),\n",
    "    end=\"\",\n",
    ")\n",
    "print(\n",
    "    \"Precision:\\t{}\\t\\tRecall:\\t{}\".format(\n",
    "        round(precision_score(y_test, y_pred), 4),\n",
    "        round(recall_score(y_test, y_pred), 4),\n",
    "    ),\n",
    "    end=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6703 melrose ave.   los angeles californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1915 fillmore st.   san francisco italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3570 las vegas blvd. s   las vegas continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>260 e. paces ferry road atlantacontinental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3130 piedmont road atlantaamerican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>3393 peachtree rd. atlantacontinental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>730 n. la cienega blvd.   los angeles french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>224 ponce de leon ave. atlantasouthern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>3645 las vegas blvd. s   las vegas buffets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>249 e. 50th st.   new york french</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "6        6703 melrose ave.   los angeles californian\n",
       "501        1915 fillmore st.   san francisco italian\n",
       "70    3570 las vegas blvd. s   las vegas continental\n",
       "384       260 e. paces ferry road atlantacontinental\n",
       "76                3130 piedmont road atlantaamerican\n",
       "..                                               ...\n",
       "422            3393 peachtree rd. atlantacontinental\n",
       "133     730 n. la cienega blvd.   los angeles french\n",
       "86            224 ponce de leon ave. atlantasouthern\n",
       "424       3645 las vegas blvd. s   las vegas buffets\n",
       "44                 249 e. 50th st.   new york french\n",
       "\n",
       "[167 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_1[np.array(y_test) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>8284 melrose ave.   los angeles   french bistro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1870 fillmore st.   san francisco american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3595 las vegas blvd. s.   las vegas continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>490 e. paces ferry rd. ne atlantacontinental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1023 abbot kinney blvd. venice  american ( ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2355 peachtree rd. ne atlantaitalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>903 n. la cienega blvd.   w. hollywood   fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>600 ponce de leon ave. atlantaitalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3799 las vegas blvd. s.   las vegas seafood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>243 e. 58th st.   new york city italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "230   8284 melrose ave.   los angeles   french bistro \n",
       "214         1870 fillmore st.   san francisco american\n",
       "130    3595 las vegas blvd. s.   las vegas continental\n",
       "300       490 e. paces ferry rd. ne atlantacontinental\n",
       "26    1023 abbot kinney blvd. venice  american ( ne...\n",
       "..                                                 ...\n",
       "292               2355 peachtree rd. ne atlantaitalian\n",
       "229   903 n. la cienega blvd.   w. hollywood   fren...\n",
       "156              600 ponce de leon ave. atlantaitalian\n",
       "125        3799 las vegas blvd. s.   las vegas seafood\n",
       "251            243 e. 58th st.   new york city italian\n",
       "\n",
       "[167 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_2[np.array(y_test) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df_new = pd.read_csv(path + \"test.csv\")\n",
    "# drop_single = [i for i in test_df_new.ID.unique() if sum(test_df_new.ID == i) <2]\n",
    "# test_df_new.set_index('ID', inplace=True)\n",
    "# test_df_new.drop(drop_single, inplace=True)\n",
    "\n",
    "# # Generate pairs\n",
    "# pairs = []\n",
    "# for i in test_df_new.index.unique():\n",
    "#     temp = test_df_new[test_df_new.index == i]\n",
    "#     # Generate a pair on the same row and append them to pairs\n",
    "#     pair = [temp.iloc[0, 1], temp.iloc[1, 1]]\n",
    "#     pairs.append(pair)\n",
    "\n",
    "# test_df_new = pd.DataFrame(pairs, columns=['address', 'duplicated_address'])\n",
    "\n",
    "test_df_new.fillna(\"\", inplace=True)\n",
    "test_df_new.reset_index(inplace=True)\n",
    "test_df_1 = test_df_new.loc[:, [\"address\"]]\n",
    "test_df_1[\"content\"] = (\n",
    "    test_df_1[\"address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    "    .str.replace(\"null\", \"\")\n",
    "    .str.replace(\"nan\", \"\")\n",
    ")\n",
    "test_df_2 = test_df_new.loc[:, [\"duplicated_address\"]]\n",
    "test_df_2[\"content\"] = (\n",
    "    test_df_2[\"duplicated_address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    "    .str.replace(\"null\", \"\")\n",
    "    .str.replace(\"nan\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(n, df1, df2):\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    for i in range(0, 1):\n",
    "        test_df_1a, test_df_1b = create_test(n, df1, df2)\n",
    "        X1, X2, drop = data_loader(test_df_1a, test_df_1b)\n",
    "\n",
    "        pred_list = np.array([])\n",
    "        y_true = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        # att1_list = []\n",
    "        # att2_list = []\n",
    "        for a, b in tqdm(zip(X1, X2)):\n",
    "            # Send data to graphic card - Cuda0\n",
    "            a, b = to_cuda(a, device), to_cuda(b, device)\n",
    "            with torch.no_grad():\n",
    "                a, b = model(a, b)\n",
    "                a, b = a.cpu(), b.cpu()\n",
    "                a = a.reshape(a.shape[0], -1)\n",
    "                b = b.reshape(b.shape[0], -1)\n",
    "                #         att1 = att1.cpu()\n",
    "                #         att2 = att2.cpu()\n",
    "                dist = np.array(\n",
    "                    [\n",
    "                        cosine_similarity([a[i].numpy()], [b[i].numpy()])\n",
    "                        for i in range(0, len(a))\n",
    "                    ]\n",
    "                ).flatten()\n",
    "\n",
    "                y_true_curr = np.zeros(len(dist))\n",
    "                y_true = np.concatenate([y_true, y_true_curr])\n",
    "                if len(y_true) >= n:\n",
    "                    y_true[n:] = 1\n",
    "\n",
    "                y_pred_curr = np.ones(len(dist))\n",
    "                y_pred_curr[np.where(dist <= 0.72)[0]] = 0\n",
    "                y_pred = np.concatenate([y_pred, y_pred_curr])\n",
    "\n",
    "                pred_list = np.concatenate([pred_list, dist])\n",
    "        #         att1_list.append(att1)\n",
    "        #         att2_list.append(att2)\n",
    "        total_acc += accuracy_score(y_true, y_pred)\n",
    "        total_f1 += f1_score(y_true, y_pred)\n",
    "        print(\n",
    "            \"Accuracy:\\t{}\\t\\tF1-score:\\t{}\\t\\t\".format(\n",
    "                round(accuracy_score(y_true, y_pred), 4),\n",
    "                round(f1_score(y_true, y_pred), 4),\n",
    "            ),\n",
    "            end=\"\",\n",
    "        )\n",
    "        print(\n",
    "            \"Precision:\\t{}\\t\\tRecall:\\t{}\\t\\t\".format(\n",
    "                round(precision_score(y_true, y_pred), 4),\n",
    "                round(recall_score(y_true, y_pred), 4),\n",
    "            ),\n",
    "            end=\"\",\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"\\nAccuracy:\\t{}\\t\\tF1-score:\\t{}\\t\\t\".format(\n",
    "            round(total_acc, 4), round(total_f1, 4)\n",
    "        ),\n",
    "        end=\"\",\n",
    "    )\n",
    "    return test_df_1a, test_df_1b\n",
    "\n",
    "\n",
    "test_df_1a, test_df_1b = test(5000, test_df_1, test_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    \"/data/dac/dedupe-project/test/new/GT_added.csv\", encoding=\"ISO-8859-1\"\n",
    ")\n",
    "mistakes_df = pd.read_excel(\"/data/dac/dedupe-project/test/new/mistakes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mistakes = [\n",
    "    \"misunderstanding\",\n",
    "    \"typing error (translate)\",\n",
    "    \"don’t know zipcode\",\n",
    "]\n",
    "mistake_dict = {\n",
    "    mistake: list(mistakes_df[mistake].dropna().index) for mistake in mistakes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.fillna(\"\", inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df_1 = test_df.loc[:, [\"address\"]]\n",
    "test_df_1[\"content\"] = (\n",
    "    test_df_1[\"address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    ")\n",
    "test_df_2 = test_df.loc[:, [\"duplicated_address\"]]\n",
    "test_df_2[\"content\"] = (\n",
    "    test_df_2[\"duplicated_address\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"\\n\", \" \")\n",
    "    .str.replace(r\"[ ]+\", \" \", regex=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X1, X2, truncate = data_loader(test_df_2, test_df_1)\n",
    "test_df_1.drop(truncate, inplace=True)\n",
    "# test_df_1.reset_index(inplace=True)\n",
    "test_df_2.drop(truncate, inplace=True)\n",
    "# test_df_2.reset_index(inplace=True)\n",
    "\n",
    "pred_list = np.array([])\n",
    "y_true = np.array([])\n",
    "y_pred = np.array([])\n",
    "att1_list = []\n",
    "att2_list = []\n",
    "for a, b in tqdm(zip(X1, X2)):\n",
    "    # Send data to graphic card - Cuda0\n",
    "    a, b = to_cuda(a), to_cuda(b)\n",
    "    with torch.no_grad():\n",
    "        a, b = model(a, b)\n",
    "        a, b = a.cpu(), b.cpu()\n",
    "        a = a.reshape(a.shape[0], -1)\n",
    "        b = b.reshape(b.shape[0], -1)\n",
    "        #         att1 = att1.cpu()\n",
    "        #         att2 = att2.cpu()\n",
    "        dist = np.array(\n",
    "            [\n",
    "                cosine_similarity([a[i].numpy()], [b[i].numpy()])\n",
    "                for i in range(0, len(a))\n",
    "            ]\n",
    "        ).flatten()\n",
    "\n",
    "        y_true_curr = np.ones(len(dist))\n",
    "        y_true = np.concatenate([y_true, y_true_curr])\n",
    "\n",
    "        y_pred_curr = np.ones(len(dist))\n",
    "        y_pred_curr[np.where(dist <= 0.83)[0]] = 0\n",
    "        y_pred = np.concatenate([y_pred, y_pred_curr])\n",
    "\n",
    "        pred_list = np.concatenate([pred_list, dist])\n",
    "#         att1_list.append(att1)\n",
    "#         att2_list.append(att2)\n",
    "\n",
    "print(\n",
    "    \"Accuracy:\\t{}\\t\\tF1-score:\\t{}\\t\\t\".format(\n",
    "        round(accuracy_score(y_true, y_pred), 4), round(f1_score(y_true, y_pred), 4)\n",
    "    ),\n",
    "    end=\"\",\n",
    ")\n",
    "print(\n",
    "    \"Precision:\\t{}\\t\\tRecall:\\t{}\\t\\t\".format(\n",
    "        round(precision_score(y_true, y_pred), 4),\n",
    "        round(recall_score(y_true, y_pred), 4),\n",
    "    ),\n",
    "    end=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in mistake_dict.items():\n",
    "    y_t = y_true[value]\n",
    "    y_p = y_pred[value]\n",
    "    print(key)\n",
    "    print(\n",
    "        \"Accuracy:\\t{}\\t\\tF1-score:\\t{}\\t\\t\".format(\n",
    "            round(accuracy_score(y_t, y_p), 4), round(f1_score(y_t, y_p), 4)\n",
    "        ),\n",
    "        end=\"\",\n",
    "    )\n",
    "    print(\n",
    "        \"Precision:\\t{}\\t\\tRecall:\\t{}\\t\\t\".format(\n",
    "            round(precision_score(y_t, y_p), 4), round(recall_score(y_t, y_p), 4),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df_1.to_csv(\"/data/dac/dedupe-project/test/new/GT_added.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
